{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 576 Final Project - Match Videos with Video Color Themes\n",
    "### author: tong wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.measure import shannon_entropy\n",
    "import cv2\n",
    "import math\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. read query videos and store them as list of image arrays of shape (288, 352, 3)\n",
    "### Note: each query video takes about 30s to read and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one rgb img\n",
    "def readRGBimg(path_to_file, filename):\n",
    "    byte_list = []\n",
    "    with open(path_to_file+filename, \"rb\") as f:\n",
    "        byte = f.read(1)\n",
    "        while byte != b\"\":\n",
    "            byte_list.append(byte)\n",
    "            byte = f.read(1)\n",
    "\n",
    "    img_data = np.zeros((288,352,3)).astype(np.uint8)\n",
    "    height = 288\n",
    "    width = 352\n",
    "    ind = 0\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            a=0\n",
    "            r=int.from_bytes(byte_list[ind], byteorder='big')\n",
    "            g=int.from_bytes(byte_list[ind+height*width], byteorder='big')\n",
    "            b=int.from_bytes(byte_list[ind+height*width*2], byteorder='big')\n",
    "\n",
    "            img_data[y][x][0] = r;\n",
    "            img_data[y][x][1] = g;\n",
    "            img_data[y][x][2] = b;\n",
    "\n",
    "            ind+=1\n",
    "    return img_data\n",
    "\n",
    "# generate num_files # of filenames as format fnString+(001,002,...,150)+fileformat(.rgb)\n",
    "def generateFileNames(num_files, fnString, fileformat):\n",
    "    retFileNames = []\n",
    "    for i in range(1, num_files + 1, 1):\n",
    "        if (i<10):\n",
    "            fnStr = \"00\"+str(i)\n",
    "        elif (i<100):\n",
    "            fnStr = \"0\"+str(i)\n",
    "        else:\n",
    "            fnStr = str(i)\n",
    "        currRetName = fnString+fnStr+fileformat\n",
    "        retFileNames.append(currRetName)\n",
    "    return retFileNames\n",
    "\n",
    "# reads a folder of query video images that of .rgb format\n",
    "# returns list of 150 images array, each of shape (288, 352, 3)\n",
    "def readRGBvideo(path_to_file, fnString):\n",
    "    retImgsList = []\n",
    "    filenamesList = generateFileNames(150, fnString, \".rgb\")\n",
    "    for i in range (150):\n",
    "        retImgsList.append(readRGBimg(path_to_file,filenamesList[i]))\n",
    "    return retImgsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3_ query video takes 22.75 MB of memory\n",
      "Q4_ query video takes 22.75 MB of memory\n",
      "Q5_ query video takes 22.75 MB of memory\n"
     ]
    }
   ],
   "source": [
    "# read and store new uploaded SeenExactMatch query videos.\n",
    "# takes about 90s. 30s each.\n",
    "\n",
    "path_to_file = \"./query_videos/SeenExactMatch/Q3/\"\n",
    "fnString = \"Q3_\"\n",
    "Q3query = readRGBvideo(path_to_file, fnString)\n",
    "print(fnString,\"query video takes\",getsizeof(Q3query)/64, \"MB of memory\")\n",
    "\n",
    "path_to_file = \"./query_videos/SeenExactMatch/Q4/\"\n",
    "fnString = \"Q4_\"\n",
    "Q4query = readRGBvideo(path_to_file, fnString)\n",
    "print(fnString,\"query video takes\",getsizeof(Q4query)/64, \"MB of memory\")\n",
    "\n",
    "path_to_file = \"./query_videos/SeenExactMatch/Q5/\"\n",
    "fnString = \"Q5_\"\n",
    "Q5query = readRGBvideo(path_to_file, fnString)\n",
    "print(fnString,\"query video takes\",getsizeof(Q5query)/64, \"MB of memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HQ1_ query video takes 22.75 MB of memory\n",
      "HQ2_ query video takes 22.75 MB of memory\n",
      "HQ4_ query video takes 22.75 MB of memory\n"
     ]
    }
   ],
   "source": [
    "# read and store new uploaded SeenInexactMatch query videos.\n",
    "# takes about 90s. 30s each.\n",
    "\n",
    "path_to_file = \"./query_videos/SeenInexactMatch/HQ1/\"\n",
    "fnString = \"HQ1_\"\n",
    "HQ1query = readRGBvideo(path_to_file, fnString)\n",
    "print(fnString,\"query video takes\",getsizeof(HQ1query)/64, \"MB of memory\")\n",
    "\n",
    "path_to_file = \"./query_videos/SeenInexactMatch/HQ2/\"\n",
    "fnString = \"HQ2_\"\n",
    "HQ2query = readRGBvideo(path_to_file, fnString)\n",
    "print(fnString,\"query video takes\",getsizeof(HQ2query)/64, \"MB of memory\")\n",
    "\n",
    "path_to_file = \"./query_videos/SeenInexactMatch/HQ4/\"\n",
    "fnString = \"HQ4_\"\n",
    "HQ4query = readRGBvideo(path_to_file, fnString)\n",
    "print(fnString,\"query video takes\",getsizeof(HQ4query)/64, \"MB of memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first query video takes 22.75 MB of memory\n",
      "second query video takes 22.75 MB of memory\n"
     ]
    }
   ],
   "source": [
    "# read old query videos\n",
    "\n",
    "path_to_file = \"./query_videos/first/\"\n",
    "fnString = \"first\"\n",
    "firstquery = readRGBvideo(path_to_file, fnString)\n",
    "print(fnString,\"query video takes\",getsizeof(firstquery)/64, \"MB of memory\")\n",
    "\n",
    "path_to_file = \"./query_videos/second/\"\n",
    "fnString = \"second\"\n",
    "secondquery = readRGBvideo(path_to_file, fnString)\n",
    "print(fnString,\"query video takes\",getsizeof(secondquery)/64, \"MB of memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Utilities\n",
    "\n",
    "- checkEntropy(inputImg) and checkInterframeEntropyDiff(img1, img2) are two conditions to calculate pallette of an image.\n",
    "    - checkEntropy(inputImg) checks if an image have much information that worth extracting dominant colors (i.e. entropy is large enough). Current threshold is 0.1.\n",
    "    - checkInterframeEntropyDiff(img1, img2) checks if two consecutive frames have much information change (i.e. difference of entropy btwn two frames is large enough). Current threshold is 0.05, which is very small. Normally, diff of entropy >1 means a **complete scene change**\n",
    "\n",
    "- colorMetric(c1,c2) calculates distance between two colors. It's a low cost approximation that avoids converting RGB to CIE LUV color space. Source: http://www.compuphase.com/cmetric.htm\n",
    "\n",
    "- colorMetricNorm(c1, c2) uses the same approximation with colorMetric(c1,c2), but normalized distance to be btwn [0,1]. A problem of using normalized distance is that the matching score went down in some cases.\n",
    "\n",
    "- show|saveColorPalette() show or save a color theme w.r.t to each color's frequency. Current saved image size is 100x100. To adjust size, modify **plt.figure(figsize=(1, 1), dpi=100)**. Final size is figsize x dpi= (1, 1) x 100 = (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below if you want to tune parameters for entropy checking\n",
    "# img1 = io.imread(\"./CS576FinalProjData/JPGdatabase_videos/JPGmusicvideo/musicvideo316.jpg\")\n",
    "# img2 = io.imread(\"./CS576FinalProjData/JPGdatabase_videos/JPGmusicvideo/musicvideo315.jpg\")\n",
    "# entropy1 = shannon_entropy(img1)\n",
    "# entropyDiff = abs(shannon_entropy(img1) - shannon_entropy(img2))\n",
    "# print(entropy1)\n",
    "# print(entropyDiff)\n",
    "# plt.imshow(img1)\n",
    "# plt.show()\n",
    "# plt.imshow(img2)\n",
    "# plt.show()\n",
    "\n",
    "def checkEntropy(inputImg):\n",
    "    entropy = shannon_entropy(inputImg)\n",
    "    if (entropy > 0.1):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def checkInterframeEntropyDiff(img1, img2):\n",
    "    entropyDiff = abs(shannon_entropy(img1) - shannon_entropy(img2))\n",
    "    if (entropyDiff > 0.03):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# calculate color distance\n",
    "c1 = np.array([255,255,255])\n",
    "c2 = np.array([0,0,0])\n",
    "def colorMetric(c1, c2):\n",
    "    rmean = (c1[0]+c2[0])/2\n",
    "    dr = c1[0]-c2[0]\n",
    "    dg = c1[1]-c2[1]\n",
    "    db = c1[2]-c2[2]\n",
    "    dist = np.sqrt((2+rmean/256)*dr*dr + 4*dg*dg + (2+(255-rmean)/256)*db*db)\n",
    "    # 765 is distance btwn white and black calculated use this metric.\n",
    "    return dist/765\n",
    "\n",
    "\n",
    "# normalized color distance to range 0 - 1. \n",
    "def colorMetricNorm(c1, c2):\n",
    "    rmean = (c1[0]+c2[0])/2/256\n",
    "    dr = (c1[0]-c2[0])/256\n",
    "    dg = (c1[1]-c2[1])/256\n",
    "    db = (c1[2]-c2[2])/256\n",
    "    dist = np.sqrt((2+rmean)*dr*dr + 4*dg*dg + (2+(1-rmean))*db*db)\n",
    "    # 765 is distance btwn white and black calculated use this metric.\n",
    "    return dist\n",
    "\n",
    "# show || save a color palette\n",
    "# 576 = 288*2 = height*2 removes artifacts at bottom of image\n",
    "def showColorPalette(palette, freq, title):\n",
    "    rows = np.int_(576*freq)\n",
    "    dom_patch = np.zeros(shape=(576, 576, 3), dtype=np.uint8)\n",
    "    for i in range(len(rows) - 1):\n",
    "        dom_patch[rows[i]:rows[i + 1], :, :] += np.uint8(palette[i])\n",
    "    plt.imshow(dom_patch)\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def saveColorPalette(palette, freq, filename):\n",
    "    rows = np.int_(576*freq)\n",
    "    dom_patch = np.zeros(shape=(576, 576, 3), dtype=np.uint8)\n",
    "    for i in range(len(rows) - 1):\n",
    "        dom_patch[rows[i]:rows[i + 1], :, :] += np.uint8(palette[i])\n",
    "    plt.figure(figsize=(1, 1), dpi=100)\n",
    "    plt.imshow(dom_patch)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename, transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get color descriptor for video.\n",
    "### 3.1 implementations\n",
    "#### strategy:\n",
    "    video's color palette = []\n",
    "    for all frames of a video\n",
    "        if both checkEntropy and checkInterframeEntropyDiff holds\n",
    "            extraxt 7 dominant colors for such frame with kmeans clustering\n",
    "            append color palette of such frame to video's color palette\n",
    "    find 5 dominant colors from video's color palette by doing kmeans clustering again\n",
    "    \n",
    "    Hence, each video's color descriptor is five colors\n",
    "\n",
    "#### about cv2.kmeans\n",
    "   - kmeans args: data, k, bestlabels, attempts, flags\n",
    "   - Return values of cv2.kmeans: each palette has k colors. In a **palette**, each color has a lable, so **labels** var stores lables for colors. **counts** is a 1xk array that stores number of appearence for each color in palette by counting unique labels. **freqs** is 1x(k+1) array that stores relative frequency of color in percentage form.\n",
    "   - in **criteria** cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER means stop the iteration when any of max_iter or eps is met\n",
    "   - **flags** is how initial centers are taken, random center is normally used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFrameColorTheme(img):\n",
    "    colorTheme = []\n",
    "    n_colors_frame = 5\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "    # data for kmeans. each row is a pixel RGB value\n",
    "    pixels = np.float32(img.reshape(-1, 3))\n",
    "\n",
    "    # find 3 dominant colors with k-clustering\n",
    "    _, labels, palette = cv2.kmeans(pixels, n_colors_frame, None, criteria, 10, flags)\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    # indices reflect the importance of colors in palette based on how big is the value in counts\n",
    "    indices = np.argsort(counts)[::-1]\n",
    "    \n",
    "    # append colors based on reordered indices\n",
    "    for i in range(n_colors_frame):\n",
    "        colorTheme.append(palette[indices[i]])\n",
    "\n",
    "    # calculates frequency of each color in palette\n",
    "    freqs = np.cumsum(np.hstack([[0], counts[indices]/counts.sum()]))\n",
    "    \n",
    "    return np.asarray(colorTheme), freqs\n",
    "\n",
    "# plt.imshow()\n",
    "\n",
    "def getDataVideoColorDescriptor (path_to_data_dir, num_files, fnString):\n",
    "    # generate filenames for reading local images\n",
    "    filenames = generateFileNames(num_files, fnString, \".jpg\")\n",
    "\n",
    "    videoColorData = []\n",
    "    for imgInd in range  (num_files):\n",
    "        currImg = io.imread(path_to_data_dir+filenames[imgInd])\n",
    "        if(checkEntropy(currImg) == False):\n",
    "            continue\n",
    "        # if not first and last frame, check entropy difference\n",
    "        if (imgInd != 0 and imgInd != num_files - 1):\n",
    "            nextImg = io.imread(path_to_data_dir+filenames[imgInd+1])\n",
    "            if (checkInterframeEntropyDiff(nextImg, currImg) == False):\n",
    "                continue\n",
    "            \n",
    "        currImgTheme, currFreq = getFrameColorTheme(currImg)\n",
    "        videoColorData.append(currImgTheme)\n",
    "\n",
    "    # reshape data so that it can be used by cv2.kmeans\n",
    "    videoColorData = np.asarray(videoColorData)\n",
    "    videoColorData = videoColorData.reshape(-1,3)\n",
    "    \n",
    "    # do k-clustering again wrt videoColorData (complete video), pick 5 most dominant colors as color theme\n",
    "    n_colors_video = 5\n",
    "    # set epsilon to .01 so that it is more accurate when do kmeans on compele videos\n",
    "    criteria_video = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .01)\n",
    "    flags_video = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "    _, labels_video, palette_video = cv2.kmeans(videoColorData, n_colors_video, None, criteria_video, 10, flags_video)\n",
    "    _, counts_video = np.unique(labels_video, return_counts=True)\n",
    "    # reorder colors based on counts\n",
    "    indices_video = np.argsort(counts_video)[::-1]\n",
    "    ordered_palette = np.zeros(shape=palette_video.shape, dtype=np.float32)\n",
    "    for i in range(n_colors_video):\n",
    "        ordered_palette[i] = palette_video[indices_video[i]]\n",
    "    freqs_video = np.cumsum(np.hstack([[0], counts_video[indices_video]/counts_video.sum()]))\n",
    "    return ordered_palette, freqs_video\n",
    "\n",
    "def getQueryVideoColorDescriptor(list_of_frames):\n",
    "    videoColorData = []\n",
    "    for imgInd in range  (len(list_of_frames)):\n",
    "        currImg = list_of_frames[imgInd]\n",
    "    \n",
    "        if(checkEntropy(currImg) == False):\n",
    "            continue\n",
    "        if (imgInd!=0 and imgInd != len(list_of_frames) - 1):\n",
    "            nextImg = list_of_frames[imgInd+1]\n",
    "            if (checkInterframeEntropyDiff(nextImg, currImg) == False):\n",
    "                continue\n",
    "\n",
    "        currImgTheme, currFreq = getFrameColorTheme(currImg)\n",
    "        videoColorData.append(currImgTheme)\n",
    "\n",
    "    # reshape data so that it can be used by cv2.kmeans\n",
    "    videoColorData = np.asarray(videoColorData)\n",
    "    videoColorData = videoColorData.reshape(-1,3)\n",
    "    \n",
    "    # do k-clustering again wrt videoColorData (complete video), pick 5 most dominant colors as color theme\n",
    "    n_colors_video = 5\n",
    "    # set epsilon to .01 so that it is more accurate when do kmeans on compele videos\n",
    "    criteria_video = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .01)\n",
    "    flags_video = cv2.KMEANS_RANDOM_CENTERS\n",
    "\n",
    "    _, labels_video, palette_video = cv2.kmeans(videoColorData, n_colors_video, None, criteria_video, 10, flags_video)\n",
    "    _, counts_video = np.unique(labels_video, return_counts=True)\n",
    "    # reorder colors based on counts\n",
    "    indices_video = np.argsort(counts_video)[::-1]\n",
    "    ordered_palette = np.zeros(shape=palette_video.shape, dtype=np.float32)\n",
    "    for i in range(n_colors_video):\n",
    "        ordered_palette[i] = palette_video[indices_video[i]]\n",
    "    freqs_video = np.cumsum(np.hstack([[0], counts_video[indices_video]/counts_video.sum()]))\n",
    "    return ordered_palette, freqs_video\n",
    "# pal, freq = getQueryVideoColorDescriptor(testimgList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 extract color themes for all frames without entropy checking\n",
    "- return num_filesx5x3 array of colors\n",
    "- note: uses generateFileNames() and getFrameColorTheme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 5, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADEUlEQVR4nO3YsUkEURRAUUemAFvQwFIEG1FLUisRbEINxGgFK7CDb77MTqSzFzwn/C95yeXBn8YYJ0DP6bEXAJaJE6LECVHihChxQtS8Nrx/uPGVC3/s7vZxWnp3OSFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6ImteGby8fW+0B7HE5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBA1jTEODi/Ozw4PgV+x+/yelt5dTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi5rXh0/PrVnsAe1xOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0TNa8Ovq+ut9oB/63L3vvjuckKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQNY0xjr0DsMDlhChxQpQ4IUqcECVOiBInRP0ADska1JQr9QMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getFbyFColorDesc (path_to_data_dir, num_files, fnString):\n",
    "    # generate filenames for reading local images\n",
    "    colorThemes = []\n",
    "    filenames = generateFileNames(num_files, fnString, \".jpg\")\n",
    "\n",
    "    videoColorData = []\n",
    "    for imgInd in range  (num_files):\n",
    "        currImg = io.imread(path_to_data_dir+filenames[imgInd])\n",
    "        currImgTheme, _ = getFrameColorTheme(currImg)\n",
    "        colorThemes.append(currImgTheme)\n",
    "    return np.asarray(colorThemes)\n",
    "\n",
    "# example use:\n",
    "numfiles = 600\n",
    "testDirPath = \"./CS576FinalProjData/JPGdatabase_videos/JPGflowers/\"\n",
    "testFnString = \"flowers\"\n",
    "testPalette = getFbyFColorDesc(testDirPath, numfiles, testFnString)\n",
    "print(testPalette.shape)\n",
    "\n",
    "# testFreq = np.array([0,0.2,0.4,0.6,0.8,1.0])\n",
    "# showAndSaveVideoColorPalette(testPalette[5], testFreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 get color descriptor for query videos\n",
    "#### note: takes 96s for 8 queries. 12s each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1palette, query1freq = getQueryVideoColorDescriptor(firstquery)\n",
    "query2palette, query2freq = getQueryVideoColorDescriptor(secondquery)\n",
    "\n",
    "queryQ3palette, queryQ3freq = getQueryVideoColorDescriptor(Q3query)\n",
    "queryQ4palette, queryQ4freq = getQueryVideoColorDescriptor(Q4query)\n",
    "queryQ5palette, queryQ5freq = getQueryVideoColorDescriptor(Q5query)\n",
    "\n",
    "queryHQ1palette, queryHQ1freq = getQueryVideoColorDescriptor(HQ1query)\n",
    "queryHQ2palette, queryHQ2freq = getQueryVideoColorDescriptor(HQ2query)\n",
    "queryHQ4palette, queryHQ4freq = getQueryVideoColorDescriptor(HQ4query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 get color descriptor for database videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowers done\n",
      "interview done\n",
      "movie done\n",
      "musicvideo done\n",
      "sports done\n",
      "starcraft done\n",
      "traffic done\n"
     ]
    }
   ],
   "source": [
    "numfiles = 600\n",
    "\n",
    "flowersDirPath = \"./CS576FinalProjData/JPGdatabase_videos/JPGflowers/\"\n",
    "fnString = \"flowers\"\n",
    "flowersPalette, flowersFreq = getDataVideoColorDescriptor(flowersDirPath, numfiles, fnString)\n",
    "print(fnString,\"done\")\n",
    "\n",
    "interviewDirPath = \"./CS576FinalProjData/JPGdatabase_videos/JPGinterview/\"\n",
    "fnString = \"interview\"\n",
    "interviewPalette, interviewFreq = getDataVideoColorDescriptor(interviewDirPath, numfiles, fnString)\n",
    "print(fnString,\"done\")\n",
    "\n",
    "movieDirPath = \"./CS576FinalProjData/JPGdatabase_videos/JPGmovie/\"\n",
    "fnString = \"movie\"\n",
    "moviePalette, movieFreq = getDataVideoColorDescriptor(movieDirPath, numfiles, fnString)\n",
    "print(fnString,\"done\")\n",
    "\n",
    "musicvideoDirPath = \"./CS576FinalProjData/JPGdatabase_videos/JPGmusicvideo/\"\n",
    "fnString = \"musicvideo\"\n",
    "musicvideoPalette, musicvideoFreq = getDataVideoColorDescriptor(musicvideoDirPath, numfiles, fnString)\n",
    "print(fnString,\"done\")\n",
    "\n",
    "sportsDirPath = \"./CS576FinalProjData/JPGdatabase_videos/JPGsports/\"\n",
    "fnString = \"sports\"\n",
    "sportsPalette, sportsFreq = getDataVideoColorDescriptor(sportsDirPath, numfiles, fnString)\n",
    "print(fnString,\"done\")\n",
    "\n",
    "starcraftDirPath = \"./CS576FinalProjData/JPGdatabase_videos/JPGstarcraft/\"\n",
    "fnString = \"starcraft\"\n",
    "starcraftPalette, starcraftFreq = getDataVideoColorDescriptor(starcraftDirPath, numfiles, fnString)\n",
    "print(fnString,\"done\")\n",
    "\n",
    "trafficDirPath = \"./CS576FinalProjData/JPGdatabase_videos/JPGtraffic/\"\n",
    "fnString = \"traffic\"\n",
    "trafficPalette, trafficFreq = getDataVideoColorDescriptor(trafficDirPath, numfiles, fnString)\n",
    "print(fnString,\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate color theme matching score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABfCAYAAACOTBv1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABSElEQVR4nO3bsU0DQRBAUQ45pwJKoAFSF+GEAqAEKqAEyHFgN0FAQAOUQEJKBUcJ7ElY39K9F2+w+prktHPTPM8XNC7rC6yZ+CHxQ+KHxA+JHxI/JH5I/NBm9OD+6cGn8AJ3j8/TX2dMfkj8kPgh8UPih8QPiR8SPyR+SPyQ+CHxQ+KHxA+JHxI/JH5I/NA0uih7c33lGXGBz68fz4jnTPyQ+CHxQ+KHxA+JHxI/JH5I/JD4IfFD4ofEDw3/mfJ6eDvlPVbJ5IfED4kfEj8kfkj8kPgh8UPih8QPiR8SPyR+SPzQ8Jby/e7WlvICL8cPW8rnTPyQ+CHxQ+KHxA+JHxI/JH5I/JD4IfFD4ofEDw1vKW/fv095j1Uy+SHxQ+KHxA+JHxI/JH5I/JD4IfFDwxtr/D+THxI/JH5I/JD4IfFD4ofED4kf+gU6vByrYrW5xgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABfCAYAAACOTBv1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABRklEQVR4nO3dwUkDURRAUUfc2oFgAVaRRYIbd5I6rMut24BVpIBArMACxhLyAw5XnHPWf/G4PAZmEvjTPM83NG7rAdZM/JD4IfFD4ofED4kfEj8kfuhu9ODm8cGr8BU+T+fp0hmbHxI/JH5I/JD4IfFD4ofED4kfEj8kfkj8kPgh8UPih8QPiR8SPyR+SPyQ+CHxQ+KHxA+JHxI/JH5I/NDwH2V3z7sl51glmx8SPyR+SPyQ+CHxQ+KHxA+JHxI/JH5I/JD4IfFD4ofED4kfGv4l6+V1v+Qcq2TzQ+KHxA+JHxI/JH5I/JD4IfFD4ofED4kfEj8kfmj4k/Lbx9eSc/w7h+3lMzY/JH5I/JD4IfFD4ofED4kfEj80jd4E/X78dk/WFfZP9+7J+svEDw0/dvh9Nj8kfkj8kPgh8UPih8QPiR8SP/QDMfQWj+51BpsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABfCAYAAACOTBv1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABN0lEQVR4nO3dMWoCQRiA0Wyw1txAhJVUAauU3v8QewjNBTZHcATlK/a9eorh42dhGJaZ1nX9oPFZb2DLxA+JHxI/JH5I/JD4IfFD4od2owu/DntH4Sfc7n/TozUmPyR+SPyQ+CHxQ+KHxA+JHxI/JH5I/JD4IfFD4ofED4kfEj8kfkj8kPgh8UPih8QPiR8SPyR+SPyQ+CHxQ+KHxA+JHxI/JH5I/JD4IfFD4ofED4kfEj80/Af6+XR85z42yeSHxA+JHxI/JH5I/JD4IfFD4ofED4kfEj8kfkj8kPgh8UPih8QPiR8avsP9+XaH+2omPyR+SPyQ+CHxQ+KHxA+JHxo+ZF1/L+/cxyaZ/JD4oWn0DfRlWbwQ94R5nh++EDccn9fz2QmJHxI/JH5I/JD4IfFD4ofED/0D9K8TN8gd7FoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABfCAYAAACOTBv1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABP0lEQVR4nO3dIU4DURRAUYZgMMUWhWALJN1Hg6ms7HK6hS6iu2AxYJDTJfQjJidh7tFfvNw8M/PFn+Z5fojxqAdYs+JDxYeKDxUfKj5UfKj4UPGhp9GDm+eXPoX/4Of3e7p3ps2Hig8VHyo+VHyo+FDxoeJDxYeKDxUfKj5UfKj4UPGh4kPFh4oPFR8qPjR8gb57fVtyjlVq86HiQ8WHig8VHyo+VHyo+FDxoeJDxYeKDxUfKj5UfKj40PBlyuf7dsk5VqnNh4oPFR8qPlR8qPhQ8aHiQ8WHig8VHyo+VHyo+FDxoeJDw5cpH/vjknOsUpsPFR8qPlR8qPhQ8aHiQ8WHig8VHyo+NPxv53z9WnKOf+dyOtw90+ZDxYeKDxUfKj5UfKj40NQD9E6bDxUfKj5UfKj4UPGh4kPFh4oP3QAHSBAeYv15qAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABfCAYAAACOTBv1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABPklEQVR4nO3dsU3DUBRAUYxYg5Sskw2QqCgipUiNlNEyAi2ihJIdcEbwT2EdKb6nfsXT1WvyXWSa5/khxqNeYMuKDxUfKj5UfKj4UPGh4kPFh55GB192z/0UvsH3z++0NNPlQ8WHig8VHyo+VHyo+FDxoeJDxYeKDxUfKj5UfKj4UPGh4kPFh4Y/I769vq+5xyZ1+VDxoeJDxYeKDxUfKj5UfKj4UPGh4kPFh4oPFR8qPjT8nv/1eVlzjzv0sTjR5UPFh4oPFR8qPlR8qPhQ8aHiQ8WHig8VHyo+VHyo+NDwe/75dFxzj03q8qHiQ8WHig8VHyo+VHyo+FDxoeJDxYeKDxUfKj40/KT8/3dYc487tF+c6PKh4kPFh4oPFR8qPlR8qPjQ1B/QO10+VHyo+FDxoeJDxYeKDxUfKj50BW3UEssA7P31AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABfCAYAAACOTBv1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABN0lEQVR4nO3dsW3CUBRAUYxYgDYd7ICUGtJFghlYN4OkScEIZgQ+hXWk+J76F09Xr/iWbHma53kTY6sHWLPiQ8WHig8VHyo+VHyo+FDxod3owf3+o0fhNzwev9OrM20+VHyo+FDxoeJDxYeKDxUfKj5UfKj4UPGh4kPFh4oPFR8qPlR8qPhQ8aHiQ8WHig8VHyo+VHyo+FDxoeJDxYeKDxUfGv444vN0XnKOVWrzoeJDxYeKDxUfKj5UfKj4UPGh4kPFh4oPFR8qPlR8qPhQ8aHiQ8WHig8VHyo+NPzqyOF6X3KOVWrzoeJDxYeKDxUfKj5UfGj4nn/7+1lyjn/o8vJEmw8VHyo+VHyo+NDwbef4/bXkHKvU5kPFh4oPFR+a+gG90+ZDxYeKDxUfKj5UfKj4UPGh4kNPHNcPOK9+ELwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAF8AAABfCAYAAACOTBv1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABQ0lEQVR4nO3csU3DUBRAUYxSQssC6YIUWALRsBpFdkmDWIImJQvQQm9G4FsiupF8Tu3i6+o1fvr2NM/zFY3r+gBrJn5I/JD4IfFD4ofED4kfEj+0GX3w+enFq/ACb+/H6a9nTH5I/JD4IfFD4ofED4kfEj8kfkj8kPgh8UPih8QPiR8a3uc/7HfnPMcqmfyQ+CHxQ+KHxA+JHxI/JH5I/JD4IfFD4ofED4kfmkY/gv44fboivsDj/dYV8Usmfkj8kPgh8UPih8QPiR8SPyR+SPyQ+CHxQ+KHxA8N7/Nvbu/s8xf4+f6yz79k4ofED4kfEj8kfkj8kPgh8UPih8QPiR8SPyR+aPivI4fD6znPsUomPyR+SPyQ+CHxQ+KHxA+JHxI/JH5I/JD4oeG7mvw/kx8SPyR+SPyQ+CHxQ+KHxA+JH/oFovMa61Qex0gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact match: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAGIElEQVR4nO3bTYhvdR3H8c+3LoGUD5FQhmbhIgSFFqUkRBFIkJuKqCy6KW0yap+byqBli1pFbboqPQkFEQUtLHrAFkWRZkFcTK49ccN8yAoX/Vr8Z2AaZga8V+f/oV4vGJhzfuccfv/Fe36/OcPMWitAn+dtewLAwcQJpcQJpcQJpcQJpcQJpcT5P2pm3jQzj2x7Hpw7cR6zmfn9zDw9M5fuO//LmVkz88qZuX1mfnjAvZfu3HvNszynW2bmx8/mMzl/4tyOh5LcvHswM9cmuWDP+F1JbpiZV+277z1J7l9rPfDcT5FtE+d23JXk5J7jDyS5c/dgrfVIknuTvH/ffSeTnDrogTNzwcx8aWb+NjMPJnndvvGPzczpmXlyZh6cmbfvnL86yeeTvH5m/j4zj+2cv2lmfjEzT8zMmZn55Hl9Yp4xcW7HT5NcNDNXz8zzk7w7yd37rjmVPXHOzKuTvCbJVw555ieSXLXz9ZZsgt/rdJI3JLk4yR1J7p6Zy9Zav0nyoST3rbVetNa6ZOf6p7L5YXBJkpuS3DYzbzuXD8u5Eef27K6eNyb5bZI/7Bv/ZpKXzswNO8cnk3x3rXX2kOe9K8mn11qPrrXOJPnc3sG11j1rrT+utf691vpakt8lue6wya21frDWun/n+l9l80Phjc/wM3IexLk9dyV5b5JbsmdLu2ut9Y8k9yQ5OTOT5H05ZEu74+VJzuw5fnjv4Myc3Hnp9NjO1vWaJP/1Umrf9dfPzPdn5uzMPJ7N6nro9Tz7xLkla62Hs3kx9NYk3zjkslPZrIg3JrkwybePeOSfklyx5/gVu9/MzJVJvpjkI0lesrN1fSDJ7E7ngOd9Ocm3klyx1ro4m99L54DreI6Ic7s+mOTNa62nDhn/UZLHknwhyVfXWk8f8ayvJ7l9Zl48M5cn+eiesRdmE+DZJJmZW7NZOXf9JcnlM/OCPecuTPLoWutfM3NdNqs8x0icW7TWOr3W+tkR4yubLe+VOWDru88d2WxlH0ryvWy2zbvPeTDJZ5Lcl02I1yb5yZ57703y6yR/npm/7pz7cJJPzcyTST6eTfwco/HP1tDJygmlxAmlxAmlxAmlThw1eNEFF3tbBM+xJ/75+IF/P7ZyQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQilxQqkTRw1ef9mVxzUPYB8rJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5QSJ5Q6cdTgO6962XHNA9jHygmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlxAmlThw1+Np33Hpc8wD2sXJCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCKXFCqRNHDX72Oz8/rnnA/607b7v5wPNWTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTiglTig1a61tzwE4gJUTSokTSokTSokTSokTSokTSv0HBnLaJxqLF18AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MV against flowers matching score: 79.21 %\n",
      "MV against interview matching score: 78.42 %\n",
      "MV against movie matching score: 82.28 %\n",
      "MV against MV matching score: 89.14 %\n",
      "MV against sports matching score: 78.65 %\n",
      "MV against starcraft matching score: 76.51 %\n",
      "MV against traffic matching score: 77.14 %\n",
      "\n",
      "\n",
      "Sports against flowers matching score: 78.07 %\n",
      "Sports against interview matching score: 76.34 %\n",
      "Sports against movie matching score: 74.55 %\n",
      "Sports against MV matching score: 73.83 %\n",
      "Sports against sports matching score: 92.49 %\n",
      "Sports against starcraft matching score: 74.93 %\n",
      "Sports against traffic matching score: 77.6 %\n",
      "\n",
      "\n",
      "Traffic against flowers matching score: 79.72 %\n",
      "Traffic against interview matching score: 75.73 %\n",
      "Traffic against movie matching score: 83.44 %\n",
      "Traffic against MV matching score: 77.61 %\n",
      "Traffic against sports matching score: 82.23 %\n",
      "Traffic against starcraft matching score: 81.45 %\n",
      "Traffic against traffic matching score: 92.22 %\n",
      "\n",
      "\n",
      "Starcraft against flowers matching score: 70.78 %\n",
      "Starcraft against interview matching score: 72.62 %\n",
      "Starcraft against movie matching score: 79.81 %\n",
      "Starcraft against MV matching score: 77.97 %\n",
      "Starcraft against sports matching score: 73.78 %\n",
      "Starcraft against starcraft matching score: 85.66 %\n",
      "Starcraft against traffic matching score: 81.97 %\n",
      "\n",
      "\n",
      "Flower against flowers matching score: 92.88 %\n",
      "Flower against interview matching score: 76.08 %\n",
      "Flower against movie matching score: 81.44 %\n",
      "Flower against MV matching score: 72.17 %\n",
      "Flower against sports matching score: 81.25 %\n",
      "Flower against starcraft matching score: 76.82 %\n",
      "Flower against traffic matching score: 77.57 %\n",
      "\n",
      "\n",
      "inexact match: \n",
      "Look like a movie against flowers matching score: 81.31 %\n",
      "Look like a movie against interview matching score: 79.55 %\n",
      "Look like a movie against movie matching score: 92.36 %\n",
      "Look like a movie against MV matching score: 88.96 %\n",
      "Look like a movie against sports matching score: 83.15 %\n",
      "Look like a movie against starcraft matching score: 82.15 %\n",
      "Look like a movie against traffic matching score: 85.37 %\n",
      "\n",
      "\n",
      "Cars with hight motion against flowers matching score: 77.7 %\n",
      "Cars with hight motion against interview matching score: 77.58 %\n",
      "Cars with hight motion against movie matching score: 89.06 %\n",
      "Cars with hight motion against MV matching score: 84.53 %\n",
      "Cars with hight motion against sports matching score: 80.61 %\n",
      "Cars with hight motion against starcraft matching score: 83.79 %\n",
      "Cars with hight motion against traffic matching score: 92.3 %\n",
      "\n",
      "\n",
      "Other flowers against flowers matching score: 84.36 %\n",
      "Other flowers against interview matching score: 81.79 %\n",
      "Other flowers against movie matching score: 77.19 %\n",
      "Other flowers against MV matching score: 77.47 %\n",
      "Other flowers against sports matching score: 79.19 %\n",
      "Other flowers against starcraft matching score: 74.54 %\n",
      "Other flowers against traffic matching score: 71.4 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calcColorMatchScore(palette1, palette2, pal1freq):\n",
    "    totalMatchScore = 0\n",
    "    contribution = np.zeros(5)\n",
    "    for i in range(5):\n",
    "        contribution[i] = pal1freq[i+1]-pal1freq[i]\n",
    "    for i in range(5):\n",
    "        bestMatchScore = 0\n",
    "        for j in range(5):\n",
    "#             currColorDist = colorMetric(palette1[i], palette2[j])\n",
    "            currColorDist = colorMetricNorm(palette1[i], palette2[j])\n",
    "            # calculate matching score\n",
    "            currMatchScore = 1/(1+currColorDist)\n",
    "            if (currMatchScore > bestMatchScore):\n",
    "                bestMatchScore = currMatchScore\n",
    "        totalMatchScore += bestMatchScore *contribution[i]\n",
    "    return np.around(totalMatchScore*100, decimals=2)\n",
    "\n",
    "def matchQueryWithDatabase(query_name, query_palette, query1freq):\n",
    "    print(query_name, \"against flowers matching score:\", calcColorMatchScore(query_palette, flowersPalette, query1freq),\"%\")\n",
    "    print(query_name, \"against interview matching score:\", calcColorMatchScore(query_palette, interviewPalette, query1freq),\"%\")\n",
    "    print(query_name, \"against movie matching score:\", calcColorMatchScore(query_palette, moviePalette, query1freq),\"%\")\n",
    "    print(query_name, \"against MV matching score:\", calcColorMatchScore(query_palette, musicvideoPalette, query1freq),\"%\")\n",
    "    print(query_name, \"against sports matching score:\", calcColorMatchScore(query_palette, sportsPalette, query1freq),\"%\")\n",
    "    print(query_name, \"against starcraft matching score:\", calcColorMatchScore(query_palette, starcraftPalette, query1freq),\"%\")\n",
    "    print(query_name, \"against traffic matching score:\", calcColorMatchScore(query_palette, trafficPalette, query1freq),\"%\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# saveColorPalette(flowersPalette, flowersFreq, \"flowers_data_colorTheme.jpg\")\n",
    "# saveColorPalette(interviewPalette, interviewFreq, \"interview_data_colorTheme.jpg\")\n",
    "# saveColorPalette(moviePalette, movieFreq, \"movie_data_colorTheme.jpg\")\n",
    "# saveColorPalette(musicvideoPalette, musicvideoFreq, \"mv_data_colorTheme.jpg\")\n",
    "# saveColorPalette(sportsPalette, sportsFreq, \"sports_data_colorTheme.jpg\")\n",
    "# saveColorPalette(starcraftPalette, starcraftFreq, \"starcraft_data_colorTheme.jpg\")\n",
    "# saveColorPalette(trafficPalette, trafficFreq, \"traffic_data_colorTheme.jpg\")\n",
    "    \n",
    "print(\"exact match: \")\n",
    "\n",
    "showColorPalette(query1palette, query1freq, \"MV query\")\n",
    "showColorPalette(musicvideoPalette, musicvideoFreq, \"MV data\")\n",
    "matchQueryWithDatabase(\"MV\",query1palette, query1freq)\n",
    "\n",
    "matchQueryWithDatabase(\"Sports\",query2palette, query2freq)\n",
    "matchQueryWithDatabase(\"Traffic\",queryQ3palette, queryQ3freq)\n",
    "matchQueryWithDatabase(\"Starcraft\",queryQ4palette, queryQ4freq)\n",
    "matchQueryWithDatabase(\"Flower\",queryQ5palette, queryQ5freq)\n",
    "\n",
    "print(\"inexact match: \")\n",
    "matchQueryWithDatabase(\"Look like a movie\",queryHQ1palette, queryHQ1freq)\n",
    "matchQueryWithDatabase(\"Cars with hight motion\",queryHQ2palette, queryHQ2freq)\n",
    "matchQueryWithDatabase(\"Other flowers\",queryHQ4palette, queryHQ4freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
